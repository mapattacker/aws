{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AWS Guide This documentation serves as a collection of AWS guides for my own consumption. Hope it can help you in the journey to master how to use services in this dominant cloud provider.","title":"Home"},{"location":"#aws-guide","text":"This documentation serves as a collection of AWS guides for my own consumption. Hope it can help you in the journey to master how to use services in this dominant cloud provider.","title":"AWS Guide"},{"location":"api-gateway/","text":"API Gateway API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. A gateway to AWS services Models & Mappings We can use API Gateway as a proxy for our backend. If we use REST API Gateway we can: Validate requests & responses with models written in JSON done at Method Request/Response Transform requests & responses with mappings written in VTL language done at Integration Request/Response Method & Integration for Requests & Responses Deployment Once a REST API is created in API Gateway, it doesn\u2019t automatically become available to invoke. We need to publish the API first. Deploying the API In API Gateway, we publish the API to a stage. Indicate deployment stage The API endpoint will be appended with the stage path, e.g., for dev stage, it would be https://a69m13u8y3.execute-api.ap-southeast-1.amazonaws.com/dev . For each stage, we can add configurations to it, e.g., throttling, logs, or canary deployment. Choosing EC2 instance type & cost savings setting when launching a Cloud9 instance API Authorization Some ways we can authorize and authenticate users of our API CORS By default, if the API is executed from a different domain, this will be blocked by AWS. However, we can enable it in API-Gateway by enabling Cross Origin Resource Sharing (CORS). Allowing CORS API-Key An API-key is a string of password that is generated to an API-user. It is passed as a header in the request with the key x-api-key . With this set, only the correct api-key have access to the API. However, as it is a password string sent within a request, it is not very secure. The upside of this method is that, we can tag a usage plan for a particular API-key, including the quota (# request/mth) and throttling (# request/sec). First we will need to create an API key. Then, we will need to create a usage plan and add the API Key to that plan. Once that is done, we will need to assign an API Stage & Method with this plan. Last, we will need to go to the Resouces > click on the API method > Method Request > Settings > change the API Key Required to true. Once that is done, we redeploy the API. Indicate deployment stage API Endpoint Resource Policy We can use the API gateway resource policy to limit access to specific IP addresses. VPC Endpoint Policy For private APIs, we can improve the security by configuring the policy at the VPC endpoints.","title":"API Gateway"},{"location":"api-gateway/#api-gateway","text":"API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. A gateway to AWS services","title":"API Gateway"},{"location":"api-gateway/#models-mappings","text":"We can use API Gateway as a proxy for our backend. If we use REST API Gateway we can: Validate requests & responses with models written in JSON done at Method Request/Response Transform requests & responses with mappings written in VTL language done at Integration Request/Response Method & Integration for Requests & Responses","title":"Models &amp; Mappings"},{"location":"api-gateway/#deployment","text":"Once a REST API is created in API Gateway, it doesn\u2019t automatically become available to invoke. We need to publish the API first. Deploying the API In API Gateway, we publish the API to a stage. Indicate deployment stage The API endpoint will be appended with the stage path, e.g., for dev stage, it would be https://a69m13u8y3.execute-api.ap-southeast-1.amazonaws.com/dev . For each stage, we can add configurations to it, e.g., throttling, logs, or canary deployment. Choosing EC2 instance type & cost savings setting when launching a Cloud9 instance","title":"Deployment"},{"location":"api-gateway/#api-authorization","text":"Some ways we can authorize and authenticate users of our API","title":"API Authorization"},{"location":"api-gateway/#cors","text":"By default, if the API is executed from a different domain, this will be blocked by AWS. However, we can enable it in API-Gateway by enabling Cross Origin Resource Sharing (CORS). Allowing CORS","title":"CORS"},{"location":"api-gateway/#api-key","text":"An API-key is a string of password that is generated to an API-user. It is passed as a header in the request with the key x-api-key . With this set, only the correct api-key have access to the API. However, as it is a password string sent within a request, it is not very secure. The upside of this method is that, we can tag a usage plan for a particular API-key, including the quota (# request/mth) and throttling (# request/sec). First we will need to create an API key. Then, we will need to create a usage plan and add the API Key to that plan. Once that is done, we will need to assign an API Stage & Method with this plan. Last, we will need to go to the Resouces > click on the API method > Method Request > Settings > change the API Key Required to true. Once that is done, we redeploy the API. Indicate deployment stage","title":"API-Key"},{"location":"api-gateway/#api-endpoint-resource-policy","text":"We can use the API gateway resource policy to limit access to specific IP addresses.","title":"API Endpoint Resource Policy"},{"location":"api-gateway/#vpc-endpoint-policy","text":"For private APIs, we can improve the security by configuring the policy at the VPC endpoints.","title":"VPC Endpoint Policy"},{"location":"boto3/","text":"Boto3 Boto3 is the AWS SDK for Python. To get started, you need to have python installed. pip install boto3 Boto3 Types Boto3 has two types of interfaces, the client and resource. The client interface is low level and provides 1-1 mapping with the AWS services' APIs, with the return responses in JSON. All service operations are supported by clients. The resource interface is a high level API, a wrapper for the client interface so that commands are more intuitive. Below is an example to download a file from S3. import boto3 def download_file ( bucket_name , origin_blob_path , dest_filename ): \"\"\"Download blob from S3 bucket. Args: bucket_name (str) origin_blob_path (str) dest_filename (str): destination filename \"\"\" s3 = boto3 . resource ( \"s3\" ) s3_bucket = s3 . Bucket ( bucket_name ) s3 . Bucket ( bucket_name ) . download_file ( origin_blob_path , dest_filename ) However, it only exposes a subset of AWS API, so functionalities might be limited , though we can assess the client interface in the resouce too as shown below. s3 = boto3 . resource ( \"s3\" ) . meta . client () Credentials To access each of the AWS services, we will need to pass our credentials either as arguments into the client or resource interfaces (not recommended!), or the SDK can detect them within the env variables, or lastly if u set them in your aws configure . S3 S3 charges for the bandwidth transferred out of S3 if its more than 1GB/mth. One of the ways to reduce this limit is to use S3 Select where you send a filter that","title":"Boto3"},{"location":"boto3/#boto3","text":"Boto3 is the AWS SDK for Python. To get started, you need to have python installed. pip install boto3","title":"Boto3"},{"location":"boto3/#boto3-types","text":"Boto3 has two types of interfaces, the client and resource. The client interface is low level and provides 1-1 mapping with the AWS services' APIs, with the return responses in JSON. All service operations are supported by clients. The resource interface is a high level API, a wrapper for the client interface so that commands are more intuitive. Below is an example to download a file from S3. import boto3 def download_file ( bucket_name , origin_blob_path , dest_filename ): \"\"\"Download blob from S3 bucket. Args: bucket_name (str) origin_blob_path (str) dest_filename (str): destination filename \"\"\" s3 = boto3 . resource ( \"s3\" ) s3_bucket = s3 . Bucket ( bucket_name ) s3 . Bucket ( bucket_name ) . download_file ( origin_blob_path , dest_filename ) However, it only exposes a subset of AWS API, so functionalities might be limited , though we can assess the client interface in the resouce too as shown below. s3 = boto3 . resource ( \"s3\" ) . meta . client ()","title":"Boto3 Types"},{"location":"boto3/#credentials","text":"To access each of the AWS services, we will need to pass our credentials either as arguments into the client or resource interfaces (not recommended!), or the SDK can detect them within the env variables, or lastly if u set them in your aws configure .","title":"Credentials"},{"location":"boto3/#s3","text":"S3 charges for the bandwidth transferred out of S3 if its more than 1GB/mth. One of the ways to reduce this limit is to use S3 Select where you send a filter that","title":"S3"},{"location":"cli/","text":"AWS CLI The AWS Command Line Interface , AWS CLI for short, allows us to easily access AWS services in the terminal. Installation If you\u2019re using Amazon EC2 instances or AWS Cloud9, the tools are already installed for you. To install in your local machine, refer to this guide . Command Syntax # command syntax aws --<optional-command> <main-command> <subcommand> <parameters> # e.g. aws s3 mb s3://bucketname We can find more info in the online CLI help docs, or just type aws <optional: command> <optional: subcommand> help , e.g. aws s3 mb help if needed. Configure To make it easier to send commands without the need to enter the credentials everytime, we can set a default profile or a specific profile name with those variables. The 4 credentials are the access and secret keys , region , and output format (default is json ). AWS Configure Cmd Desc aws configure enter access, secret & region names, for default profile aws configure --profile <name> enter access, secret & region names, based on a specific name aws s3 ls --profile <name> enter commands based on profile These credentials are stored in ~/.aws/credentials .","title":"AWS CLI"},{"location":"cli/#aws-cli","text":"The AWS Command Line Interface , AWS CLI for short, allows us to easily access AWS services in the terminal.","title":"AWS CLI"},{"location":"cli/#installation","text":"If you\u2019re using Amazon EC2 instances or AWS Cloud9, the tools are already installed for you. To install in your local machine, refer to this guide .","title":"Installation"},{"location":"cli/#command-syntax","text":"# command syntax aws --<optional-command> <main-command> <subcommand> <parameters> # e.g. aws s3 mb s3://bucketname We can find more info in the online CLI help docs, or just type aws <optional: command> <optional: subcommand> help , e.g. aws s3 mb help if needed.","title":"Command Syntax"},{"location":"cli/#configure","text":"To make it easier to send commands without the need to enter the credentials everytime, we can set a default profile or a specific profile name with those variables. The 4 credentials are the access and secret keys , region , and output format (default is json ). AWS Configure Cmd Desc aws configure enter access, secret & region names, for default profile aws configure --profile <name> enter access, secret & region names, based on a specific name aws s3 ls --profile <name> enter commands based on profile These credentials are stored in ~/.aws/credentials .","title":"Configure"},{"location":"cloud9/","text":"Cloud9 Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don\u2019t need to install files or configure your development machine to start new projects. Interface of Cloud9 IDE Starting Cloud9 Cloud9 runs on an EC2 instance, and charges based on the instance type and storage. If we choose the cheapest t2.micro , AWS estimates it to only be USD$2.05 per month. Free tier AWS (first year of account opening) has 750 free hours for EC2, so the costs should be either neligible or none at all. We should allow the cost saving settings to be on to prevent ballooning accidental costs. Choosing EC2 instance type & cost savings setting when launching a Cloud9 instance To close Cloud9 IDE, we need to go to the EC2 instance to shutdown. To start the instance, we can just go to Cloud9 service in management console and open the IDE. Credentials By default, Cloud9 has temporary credentials that will refresh every 5 mins. These credentials are the same as the IAM role that was used to create this Cloud9 instance, so the permissions to AWS resources are the same. To use a different credentials, we need to go to Cloud9 Settings > AWS Settings > Credentials > turn off AWS managed temporary credentials. Then in the terminal, AWS Configure & enter your other credentials. Switching off Temp Credentials File Uploads We can upload files & access the settings from the Welcome page.","title":"Cloud9"},{"location":"cloud9/#cloud9","text":"Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don\u2019t need to install files or configure your development machine to start new projects. Interface of Cloud9 IDE","title":"Cloud9"},{"location":"cloud9/#starting-cloud9","text":"Cloud9 runs on an EC2 instance, and charges based on the instance type and storage. If we choose the cheapest t2.micro , AWS estimates it to only be USD$2.05 per month. Free tier AWS (first year of account opening) has 750 free hours for EC2, so the costs should be either neligible or none at all. We should allow the cost saving settings to be on to prevent ballooning accidental costs. Choosing EC2 instance type & cost savings setting when launching a Cloud9 instance To close Cloud9 IDE, we need to go to the EC2 instance to shutdown. To start the instance, we can just go to Cloud9 service in management console and open the IDE.","title":"Starting Cloud9"},{"location":"cloud9/#credentials","text":"By default, Cloud9 has temporary credentials that will refresh every 5 mins. These credentials are the same as the IAM role that was used to create this Cloud9 instance, so the permissions to AWS resources are the same. To use a different credentials, we need to go to Cloud9 Settings > AWS Settings > Credentials > turn off AWS managed temporary credentials. Then in the terminal, AWS Configure & enter your other credentials. Switching off Temp Credentials","title":"Credentials"},{"location":"cloud9/#file-uploads","text":"We can upload files & access the settings from the Welcome page.","title":"File Uploads"},{"location":"iam/","text":"IAM AWS Identity and Access Management ( IAM ) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources. Root User When we first create a AWS account, it will be created as a root user, having full access over this account. It will be wise to create a user for future logins for security reasons.","title":"IAM"},{"location":"iam/#iam","text":"AWS Identity and Access Management ( IAM ) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.","title":"IAM"},{"location":"iam/#root-user","text":"When we first create a AWS account, it will be created as a root user, having full access over this account. It will be wise to create a user for future logins for security reasons.","title":"Root User"},{"location":"s3/","text":"S3 AWS S3 stands for Simple Storage Service. SDK helper functions import boto3 s3 = boto3 . resource ( 's3' ) def upload_file ( s3 , local_filepath , bucketname , s3_filepath ): s3 . meta . client . upload_file ( local_filepath , bucketname , s3_filepath ) print ( f \"upload { local_path } complete\" ) if __name__ == \"__main__\" : local_path = \"/home/dragon_stats_one.json\" bucketname = \"dragon-data\" s3_path = \"dragon_stats_one.json\" upload_file ( s3 , local_path , bucketname , s3_path )","title":"S3"},{"location":"s3/#s3","text":"AWS S3 stands for Simple Storage Service.","title":"S3"},{"location":"s3/#sdk-helper-functions","text":"import boto3 s3 = boto3 . resource ( 's3' ) def upload_file ( s3 , local_filepath , bucketname , s3_filepath ): s3 . meta . client . upload_file ( local_filepath , bucketname , s3_filepath ) print ( f \"upload { local_path } complete\" ) if __name__ == \"__main__\" : local_path = \"/home/dragon_stats_one.json\" bucketname = \"dragon-data\" s3_path = \"dragon_stats_one.json\" upload_file ( s3 , local_path , bucketname , s3_path )","title":"SDK helper functions"}]}